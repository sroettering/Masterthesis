%************************************************
\chapter{Related Work}\label{ch:relatedwork}
%************************************************

\begin{itemize}

\item{
	Gestural and Audio Metaphors as a Means of Control,
	mobile music player controllable by touch-gestures and non speech audio
}
\item{
	Vatavu User-Defined Gestures for Free-Hand TV Control,
	Agreement Analysis on 12 user defined tv control gestures,
	simple free-hand gestures found
}
\item{
	Blumendorf, Multimodal smart home user interfaces,
	interaction commands must be learnable easily and quickly, user prefers short commands over complex sentences in speech interaction
}
\item{
	Can user-derived gesture be considered as the best,
	30 participants, created own gesture set for controlling tv and air conditioning, in second test every user was presented all other gestures, highest agreed gesture from first test was not highest in second, since most users did not come up with some creative gestures.
}

\end{itemize}

Casual interaction has become a big research topic in \ac{HCI} nowadays.

Pohl and Murray-Smith \cite{pohl2013focused} have characterised the term casual interaction in contrast to focused interaction and described the \textit{focused-casual continuum}, which is a control-theoretic framework that characterizes input techniques in regard to how much flexibility, in terms of thinking and effort, they allow a user to invest into interactions. They showed in a user study that users adjust their level of engagement to the task's complexity.

On this basis, \cite{Busse2014Thesis} constructed a wrist worn silicone bracelet. When worn, a user could casually interact with a light source. Simple actions like turning the light on and off up to picking individual colors with a capacitive touch stripe. Accelerometer based gestures could be used to activate previously defined and memorized light settings. Despite being highly accessible on the wrist, a user would still have to utilize the hand without the bracelet to activate it's features making interactions rather impractical in certain situations.

Another approach places a depth camera for capturing hand gestures on the user's foot pointing upwards \cite{bailly2012shoesense}. This allows for discreet interactions thus neglecting concerns of social acceptability of performing gestures as they found out. In a lab study they compared physical and mental demand, user preferences and demonstrated a 94-99\% recognition rate.

An alternative input technique is shown in \cite{pohl2014around}. They introduce around-device devices. Input is received by observing position and rotation as well as arrangement or absence of the around-device devices. To capture this information they propose placing a smartphone equipped with a depth camera nearby.  In contrast to the aforementioned approaches, this technique is limited to stationary contexts automatically excluding any in-motion-situations.

Furthermore, casual interaction was applied to mobile music retrieval by \cite{boland2015engaging}. They investigated the listening habits of 95 last.fm\footnote{Internet radio station: \url{www.last.fm}} users and divided them into three groups. The first group consists of the engaged listeners who invest high initial engagement by e.g. selecting a specific album and afterwards only make quick and decisive interventions. The second group consists of the casual users who invest little effort in interventions at any time. The third group is a mixture of the first two groups where music listening behaviour highly depends on the context. Based on these groups they added a semantic zooming view of linear music space to a already given music retrieval interface. Zooming in on the view enables the user to make more specific music selections. A recommender system additionally infers other relevant music depending on the input specificity.

In the scope of interactions with smart home appliances \cite{kuhnel2011m} conducted a series of user study on gestural input for devices found in an average living room -- namely blinds, lamps, tv, \ac{EPG}, video recorder and answering machine. In the first study they tried to determine a gesture vocabluray. Therefor they observed eigtheen participants seated on a sofa in fully functional living room with the above mentioned devices. The participants were asked to perform a gesture, they would deem appropriate, for every action or referent as \cite{wobbrock2009user} refer to. In a second study 22 new participants should then map the gestures from the vocabulary back to the referents. The last study was performed by 10 participants to study the memorability. In a training session every participant performed every gesture five times and then rated the suitability. Finally a slide show displayed every referent for 5 seconds in a random order. If the participant could not perform the gesture in this time, the correct gesture was shown again and the referent was added to the end of the slide show again. Overall their results showed that simple and short physically or symbloc inspired gestures were rated most suitable and appeared to be most memorizable. 

Casual interaction through speech input is yet to be explored. Some research, however, was inquired in the field of smart homes. For example, \cite{blumendorf2008multimodal} prototyped a cooking assistant that was installed in their Ambient Living Testbed. Users could interact with the assistant either via touchscreen, mouse and keyboard or via speech input. The latter came in handy while being physically distracted as they were searching for ingredients or cutting vegetables. The findings from the user study based on the cooking assistant revealed that users prefer the availability of mutliple modalities as the possibility to fall back to touch oder mouse input provides an idea safety against failures of the voice recognition. Furthermore, they state a higher acceptance of command-based speech interactions instead of entering whole sentences, as short commands are easier to learn. For more complex commands, users tend to ask the system for help.

%Chapter \ref{ch:relatedwork} 


%*****************************************
%*****************************************
%*****************************************
%*****************************************
%*****************************************




