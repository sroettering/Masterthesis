%************************************************
\chapter{Related Work}\label{ch:relatedwork}
%************************************************

\begin{itemize}

\item{
	I'm Home: Smartphone-enabled gestural interaction with multi-modal smart-home systems,
	accelerometer based gesture control of tv hifi-system, lamp and window-shutter
}
\item{
	Gestural and Audio Metaphors as a Means of Control,
	mobile music player controllable by touch-gestures and non speech audio
}
\item{
	Vatavu User-Defined Gestures for Free-Hand TV Control,
	Agreement Analysis on 12 user defined tv control gestures,
	simple free-hand gestures found
}
\item{
	A Gesture Based System for Context - Sensitive Interaction with Smart Homes,
	3D acceleration gestures, wiimote, gestures have different meanings in different contexts, reducing gesture set size
}
\item{
	Blumendorf, Multimodal smart home user interfaces,
	interaction commands must be learnable easily and quickly, user prefers short commands over complex sentences in speech interaction
}
\item{
	Can user-derived gesture be considered as the best,
	30 participants, created own gesture set for controlling tv and air conditioning, in second test every user was presented all other gestures, highest agreed gesture from first test was not highest in second, since most users did not come up with some creative gestures.
}

\end{itemize}

Casual interaction has become a big research topic in \ac{HCI} nowadays.

Pohl and Murray-Smith \cite{pohl2013focused} have characterised the term casual interaction in contrast to focused interaction and described the \textit{focused-casual continuum}, which is a control-theoretic framework that characterizes input techniques in regard to how much flexibility, in terms of thinking and effort, they allow a user to invest into interactions. They showed in a user study that users adjust their level of engagement to the task's complexity.

On this basis, \cite{Busse2014Thesis} constructed a wrist worn silicone bracelet. When worn, a user could casually interact with a light source. Simple actions like turning the light on and off up to picking individual colors with a capacitive touch stripe. Accelerometer based gestures could be used to activate previously defined and memorized light settings. Despite being highly accessible on the wrist, a user would still have to utilize the hand without the bracelet to activate it's features making interactions rather impractical in certain situations.

Another approach places a depth camera for capturing hand gestures on the user's foot pointing upwards \cite{bailly2012shoesense}. This allows for discreet interactions thus neglecting concerns of social acceptability of performing gestures as they found out. In a lab study they compared physical and mental demand, user preferences and demonstrated a 94-99\% recognition rate.

An alternative input technique is shown in \cite{pohl2014around}. They introduce around-device devices. Input is received by observing position and rotation as well as arrangement or absence of the around-device devices. To capture this information they propose placing a smartphone equipped with a depth camera nearby.  In contrast to the aforementioned approaches, this technique is limited to stationary contexts automatically excluding any in-motion-situations.

Furthermore, casual interaction was applied to mobile music retrieval by \cite{boland2015engaging}. They investigated the listening habits of 95 last.fm\footnote{Internet radio station at \url{www.last.fm}} users and divided them into three groups. The first group consists of the engaged listeners who invest high initial engagement by e.g. selecting a specific album and afterwards only make quick and decisive interventions. The second group consists of the casual users who invest little effort in interventions at any time. The third group is a mixture of the first two groups where music listening behaviour highly depends on the context. Based on these groups they added a semantic zooming view of linear music space to a already given music retrieval interface. Zooming in on the view enables the user to make more specific music selections. A recommender system additionally infers other relevant music depending on the input specificity.

In the scope of interactions with smart home appliances \cite{kuhnel2011m} conducted a user study on gestural input for devices found in an average living room -- namely blinds, lamps, tv, \ac{EPG}, video recorder and answering machine.

%Chapter \ref{ch:relatedwork} 


%*****************************************
%*****************************************
%*****************************************
%*****************************************
%*****************************************




